---
title: Sklearn å…¨æŒ‡å—
date: 2026-01-20
category: MachineLearning/Basic
tags:
  - Python
  - åŸºç¡€
description: Scikit-learn (sklearn) åº“å®è·µæŒ‡å—ï¼Œæ¶µç›–æ•°æ®é¢„å¤„ç†ã€ç‰¹å¾å·¥ç¨‹ã€Pipelineæ„å»ºã€æ¨¡å‹é€‰æ‹©ã€äº¤å‰éªŒè¯ã€è¶…å‚æ•°è°ƒä¼˜ã€è¯„ä¼°æŒ‡æ ‡åŠå¸¸ç”¨æ¨¡å‹ï¼ˆçº¿æ€§æ¨¡å‹ã€æ ‘æ¨¡å‹ã€SVMç­‰ï¼‰çš„è¯¦ç»†åº”ç”¨ä¸å¯è§†åŒ–ã€‚
image: https://img.yumeko.site/file/blog/Sklearning.jpg
status: published
---

# åŸºç¡€å…¥é—¨

## è¿è¡Œæ–¹å¼

```python
# æ–¹å¼1: ç›´æ¥è¿è¡Œ
python code/01_basics.py

# æ–¹å¼2: å¯¼å…¥å•ä¸ªå‡½æ•°
from code.01_basics import demo_load_datasets
demo_load_datasets()

# æ–¹å¼3: è¿è¡Œå…¨éƒ¨
from code.01_basics import demo_all
demo_all()
```

---

## 1. æ•°æ®é›†åŠ è½½

### 1.1 å†…ç½®æ•°æ®é›†

| å‡½æ•°                   | æ•°æ®é›†   | ç±»å‹   | æ ·æœ¬æ•° |
| ---------------------- | -------- | ------ | ------ |
| `load_iris()`          | é¸¢å°¾èŠ±   | åˆ†ç±»   | 150    |
| `load_wine()`          | è‘¡è„é…’   | åˆ†ç±»   | 178    |
| `load_breast_cancer()` | ä¹³è…ºç™Œ   | äºŒåˆ†ç±» | 569    |
| `load_digits()`        | æ‰‹å†™æ•°å­— | åˆ†ç±»   | 1797   |
| `load_diabetes()`      | ç³–å°¿ç—…   | å›å½’   | 442    |

### æ•°æ®é›†å¯è§†åŒ–

ä¸‹å›¾å±•ç¤ºäº†é¸¢å°¾èŠ±æ•°æ®é›†çš„ç‰¹å¾åˆ†å¸ƒå’Œç±»åˆ«åˆ†å¸ƒï¼š

![01_datasets](https://img.yumeko.site/file/articles/sklearn/01_datasets.png)

### 1.2 load_xxx() å‚æ•°

```python
datasets.load_iris(
    return_X_y=False,    # True: ç›´æ¥è¿”å› (X, y) å…ƒç»„
    as_frame=False       # True: è¿”å› DataFrame æ ¼å¼
)
```

| å‚æ•°         | é»˜è®¤  | è¯´æ˜                                   |
| ------------ | ----- | -------------------------------------- |
| `return_X_y` | False | True æ—¶è¿”å› `(X, y)` è€Œä¸æ˜¯ Bunch å¯¹è±¡ |
| `as_frame`   | False | True æ—¶ç‰¹å¾å’Œç›®æ ‡éƒ½æ˜¯ DataFrame        |

### 1.3 ç”Ÿæˆäººå·¥æ•°æ®

| å‡½æ•°                    | ç”¨é€”   | å…³é”®å‚æ•°                                |
| ----------------------- | ------ | --------------------------------------- |
| `make_classification()` | åˆ†ç±»   | `n_classes`, `n_informative`, `weights` |
| `make_regression()`     | å›å½’   | `noise`                                 |
| `make_blobs()`          | èšç±»   | `centers`, `cluster_std`                |
| `make_moons()`          | æœˆç‰™å½¢ | `noise`                                 |
| `make_circles()`        | åŒå¿ƒåœ† | `noise`, `factor`                       |

### äººå·¥æ•°æ®é›†å¯è§†åŒ–

ä¸‹å›¾å±•ç¤ºäº†å„ç§äººå·¥ç”Ÿæˆæ•°æ®é›†ï¼š

![01_generate_data](https://img.yumeko.site/file/articles/sklearn/01_generate_data.png)

---

## 2. æ•°æ®åˆ’åˆ†

### train_test_split å‚æ•°

```python
train_test_split(
    X, y,
    test_size=0.25,      # æµ‹è¯•é›†æ¯”ä¾‹
    train_size=None,
    random_state=None,   # éšæœºç§å­
    shuffle=True,        # æ˜¯å¦æ‰“ä¹±
    stratify=None        # åˆ†å±‚æŠ½æ ·
)
```

| å‚æ•°           | é»˜è®¤ | âš ï¸ ä»€ä¹ˆæ—¶å€™æ”¹                     |
| -------------- | ---- | --------------------------------- |
| `test_size`    | 0.25 | æ•°æ®å°‘ç”¨ 0.2ï¼Œæ•°æ®å¤šç”¨ 0.1        |
| `random_state` | None | **å¿…é¡»è®¾å›ºå®šå€¼**ä¿è¯å¯å¤ç°ï¼å¦‚ 42 |
| `shuffle`      | True | æ—¶é—´åºåˆ—æ•°æ®è®¾ False              |
| `stratify`     | None | **åˆ†ç±»é—®é¢˜å¿…é¡»è®¾ `stratify=y`ï¼** |

> âš ï¸ åˆ†ç±»é—®é¢˜ä¸è®¾ `stratify=y` å¯èƒ½å¯¼è‡´æŸç±»åˆ«å…¨åœ¨è®­ç»ƒé›†æˆ–æµ‹è¯•é›†ï¼

### æ•°æ®åˆ’åˆ†å¯è§†åŒ–

ä¸‹å›¾å±•ç¤ºäº†è®­ç»ƒé›†/æµ‹è¯•é›†åˆ’åˆ†å’Œåˆ†å±‚æŠ½æ ·æ•ˆæœï¼š

![01_train_test_split](https://img.yumeko.site/file/articles/sklearn/01_train_test_split.png)

---

## 3. ä¼°è®¡å™¨ API

### 3.1 ç»Ÿä¸€æ¥å£

| æ–¹æ³•                   | è¯´æ˜      | é€‚ç”¨å¯¹è±¡         |
| ---------------------- | --------- | ---------------- |
| `fit(X, y)`            | è®­ç»ƒ      | æ‰€æœ‰             |
| `predict(X)`           | é¢„æµ‹      | åˆ†ç±»å™¨ã€å›å½’å™¨   |
| `transform(X)`         | è½¬æ¢æ•°æ®  | é¢„å¤„ç†å™¨ã€é™ç»´å™¨ |
| `fit_transform(X)`     | è®­ç»ƒ+è½¬æ¢ | é¢„å¤„ç†å™¨         |
| `score(X, y)`          | è¯„ä¼°      | åˆ†ç±»å™¨ã€å›å½’å™¨   |
| `predict_proba(X)`     | é¢„æµ‹æ¦‚ç‡  | éƒ¨åˆ†åˆ†ç±»å™¨       |
| `get_params()`         | è·å–å‚æ•°  | æ‰€æœ‰             |
| `set_params(**params)` | è®¾ç½®å‚æ•°  | æ‰€æœ‰             |

### 3.2 è®­ç»ƒåå±æ€§ (å¸¦ä¸‹åˆ’çº¿åç¼€)

```python
model.classes_          # ç±»åˆ«åˆ—è¡¨
model.n_features_in_    # è¾“å…¥ç‰¹å¾æ•°
model.feature_names_in_ # ç‰¹å¾åï¼ˆDataFrameè¾“å…¥æ—¶ï¼‰
model.coef_             # çº¿æ€§æ¨¡å‹ç³»æ•°
model.intercept_        # çº¿æ€§æ¨¡å‹æˆªè·
```

### 3.3 å¸¸è§é—®é¢˜

**Q: fit() vs fit_transform() åŒºåˆ«ï¼Ÿ**

- `fit()`: åªè®­ç»ƒï¼Œç”¨äºé¢„æµ‹æ¨¡å‹
- `fit_transform()`: è®­ç»ƒ+è½¬æ¢ï¼Œç”¨äºé¢„å¤„ç†å™¨

**Q: æµ‹è¯•é›†ä¸ºä»€ä¹ˆåªèƒ½ç”¨ transform() ä¸èƒ½ç”¨ fit_transform()ï¼Ÿ**

```python
# âœ… æ­£ç¡®
scaler.fit_transform(X_train)  # è®­ç»ƒé›†
scaler.transform(X_test)       # æµ‹è¯•é›†

# âŒ é”™è¯¯ - æ•°æ®æ³„éœ²
scaler.fit_transform(X_test)
```

**Q: random_state ä½œç”¨ï¼Ÿ**
è®¾ç½®éšæœºç§å­ä¿è¯æ¯æ¬¡ç»“æœä¸€è‡´ã€‚å¸¸ç”¨ `random_state=42`

### KNN æ¨¡å‹å¯è§†åŒ–

ä¸‹å›¾å±•ç¤ºäº† KNN åˆ†ç±»å™¨çš„å†³ç­–è¾¹ç•Œå’Œä¸åŒ k å€¼çš„å‡†ç¡®ç‡ï¼š

![01_knn](https://img.yumeko.site/file/articles/sklearn/01_knn.png)

# æ•°æ®é¢„å¤„ç†

## 1. ç¼©æ”¾å™¨å¯¹æ¯”

| ç¼©æ”¾å™¨              | å…¬å¼                                                        | è¾“å‡ºèŒƒå›´     | å¯¹å¼‚å¸¸å€¼  | é€‚ç”¨åœºæ™¯            |
| ---------------- | --------------------------------------------------------- | -------- | :---: | --------------- |
| `StandardScaler` | $z = \displaystyle\frac{x - \mu}{\sigma}$                 | æ— ç•Œ       | âš ï¸ æ•æ„Ÿ | æ­£æ€åˆ†å¸ƒæ•°æ®ï¼ŒSVM/é€»è¾‘å›å½’ |
| `MinMaxScaler`   | $x' = \displaystyle\frac{x - x_{min}}{x_{max} - x_{min}}$ | $[0,1]$  | âš ï¸ æ•æ„Ÿ | ç¥ç»ç½‘ç»œï¼Œéœ€è¦æœ‰ç•Œè¾“å‡º     |
| `RobustScaler`   | $x' = \displaystyle\frac{x - median}{IQR}$                | æ— ç•Œ       | âœ… é²æ£’  | å«å¼‚å¸¸å€¼çš„æ•°æ®         |
| `MaxAbsScaler`   | $x' = \displaystyle\frac{x}{\vert x_{max} \vert}$         | $[-1,1]$ | âš ï¸ æ•æ„Ÿ | ç¨€ç–æ•°æ®            |

### ç¼©æ”¾å™¨å¯è§†åŒ–

ä¸‹å›¾å±•ç¤ºäº†ä¸åŒç¼©æ”¾å™¨å¤„ç†å«å¼‚å¸¸å€¼æ•°æ®çš„æ•ˆæœï¼š

![02_scalers](https://img.yumeko.site/file/articles/sklearn/02_scalers.png)

### é€‰æ‹©å»ºè®®

```
æ•°æ®æœ‰å¼‚å¸¸å€¼ï¼Ÿ
â”œâ”€ æ˜¯ â†’ RobustScaler
â””â”€ å¦ â†’ éœ€è¦å›ºå®šèŒƒå›´ï¼Ÿ
         â”œâ”€ æ˜¯ â†’ MinMaxScaler
         â””â”€ å¦ â†’ StandardScaler
```

---

## 2. StandardScaler

**ä½œç”¨**: æ ‡å‡†åŒ–ï¼Œè½¬æ¢ä¸ºå‡å€¼ $\mu = 0$ã€æ ‡å‡†å·® $\sigma = 1$

**å…¬å¼**: $$z = \frac{x - \mu}{\sigma}$$

```python
StandardScaler(
    copy=True,        # æ˜¯å¦å¤åˆ¶æ•°æ®
    with_mean=True,   # æ˜¯å¦å‡å»å‡å€¼ï¼ˆä¸­å¿ƒåŒ–ï¼‰
    with_std=True     # æ˜¯å¦é™¤ä»¥æ ‡å‡†å·®
)
```

| å‚æ•°        | é»˜è®¤ | ä½œç”¨     | âš ï¸ ä»€ä¹ˆæ—¶å€™æ”¹              |
| ----------- | ---- | -------- | -------------------------- |
| `copy`      | True | å¤åˆ¶æ•°æ® | æ•°æ®é‡å¤§èŠ‚çœå†…å­˜è®¾ False   |
| `with_mean` | True | ä¸­å¿ƒåŒ–   | **ç¨€ç–çŸ©é˜µå¿…é¡»è®¾ Falseï¼** |
| `with_std`  | True | ç¼©æ”¾     | åªæƒ³ä¸­å¿ƒåŒ–ä¸ç¼©æ”¾æ—¶è®¾ False |

### è®­ç»ƒåå±æ€§

```python
scaler.mean_    # æ¯ä¸ªç‰¹å¾çš„å‡å€¼
scaler.scale_   # æ¯ä¸ªç‰¹å¾çš„æ ‡å‡†å·®
scaler.var_     # æ¯ä¸ªç‰¹å¾çš„æ–¹å·®
```

> âš ï¸ **ç¨€ç–çŸ©é˜µè­¦å‘Š**: ç¨€ç–æ•°æ®ç”¨ StandardScaler å¿…é¡» `with_mean=False`ï¼Œå¦åˆ™ä¼šç ´åç¨€ç–æ€§å¯¼è‡´å†…å­˜çˆ†ç‚¸ï¼

---

## 3. MinMaxScaler

**ä½œç”¨**: å½’ä¸€åŒ–ï¼Œç¼©æ”¾åˆ°æŒ‡å®šèŒƒå›´

**å…¬å¼**: $$x' = \frac{x - x_{min}}{x_{max} - x_{min}} \times (max - min) + min$$

```python
MinMaxScaler(
    feature_range=(0, 1),  # ç›®æ ‡èŒƒå›´
    copy=True,
    clip=False             # æ˜¯å¦è£å‰ªè¶…å‡ºèŒƒå›´çš„å€¼
)
```

| å‚æ•°            | é»˜è®¤   | ä½œç”¨     | âš ï¸ ä»€ä¹ˆæ—¶å€™æ”¹                     |
| --------------- | ------ | -------- | --------------------------------- |
| `feature_range` | (0, 1) | ç›®æ ‡èŒƒå›´ | éœ€è¦ [-1,1] æ—¶æ”¹ `(-1, 1)`        |
| `clip`          | False  | è£å‰ªè¾¹ç•Œ | æµ‹è¯•æ•°æ®å¯èƒ½è¶…å‡ºè®­ç»ƒèŒƒå›´æ—¶è®¾ True |

### è®­ç»ƒåå±æ€§

```python
scaler.data_min_   # æ¯ä¸ªç‰¹å¾çš„æœ€å°å€¼
scaler.data_max_   # æ¯ä¸ªç‰¹å¾çš„æœ€å¤§å€¼
scaler.data_range_ # max - min
```

---

## 4. RobustScaler

**ä½œç”¨**: ä½¿ç”¨ä¸­ä½æ•°å’Œ IQR ç¼©æ”¾ï¼Œå¯¹å¼‚å¸¸å€¼é²æ£’

**å…¬å¼**: 
$$x' = \frac{x - median}{Q_3 - Q_1}$$

```python
RobustScaler(
    with_centering=True,        # æ˜¯å¦å‡å»ä¸­ä½æ•°
    with_scaling=True,          # æ˜¯å¦é™¤ä»¥ IQR
    quantile_range=(25.0, 75.0) # IQR åˆ†ä½æ•°èŒƒå›´
)
```

| å‚æ•°             | é»˜è®¤     | ä½œç”¨     | âš ï¸ ä»€ä¹ˆæ—¶å€™æ”¹             |
| ---------------- | -------- | -------- | ------------------------- |
| `quantile_range` | (25, 75) | IQR èŒƒå›´ | å¼‚å¸¸å€¼æç«¯æ—¶æ”¹ `(10, 90)` |
| `with_centering` | True     | å‡ä¸­ä½æ•° | ç¨€ç–æ•°æ®è®¾ False          |

---

## 5. ç±»åˆ«ç¼–ç 

### 5.1 ç¼–ç å™¨å¯¹æ¯”

| ç¼–ç å™¨           | è¾“å‡º              | ç”¨é€”              |
| ---------------- | ----------------- | ----------------- |
| `LabelEncoder`   | æ•´æ•° $(0,1,2...)$ | ç›®æ ‡å˜é‡ $y$ ç¼–ç  |
| `OrdinalEncoder` | æ•´æ•°çŸ©é˜µ          | æœ‰åºç±»åˆ«ç‰¹å¾      |
| `OneHotEncoder`  | äºŒè¿›åˆ¶çŸ©é˜µ        | æ— åºç±»åˆ«ç‰¹å¾      |

### ç¼–ç æ–¹æ³•å¯è§†åŒ–

ä¸‹å›¾å±•ç¤ºäº† LabelEncoder å’Œ OneHotEncoder çš„åŒºåˆ«ï¼š

![02_encoding](https://img.yumeko.site/file/articles/sklearn/02_encoding.png)

### 5.2 OneHotEncoder å‚æ•°è¯¦è§£

```python
OneHotEncoder(
    categories='auto',       # ç±»åˆ«åˆ—è¡¨
    drop=None,               # ä¸¢å¼ƒç­–ç•¥
    sparse_output=True,      # è¾“å‡ºç±»å‹
    handle_unknown='error',  # æœªçŸ¥ç±»åˆ«å¤„ç†
    min_frequency=None,      # æœ€å°é¢‘ç‡
    max_categories=None      # æœ€å¤§ç±»åˆ«æ•°
)
```

| å‚æ•°             | é»˜è®¤    | ä½œç”¨         | âš ï¸ ä»€ä¹ˆæ—¶å€™æ”¹                   |
| ---------------- | ------- | ------------ | ------------------------------- |
| `sparse_output`  | True    | è¾“å‡ºç¨€ç–çŸ©é˜µ | æƒ³è¦æ™®é€šæ•°ç»„è®¾ **False**        |
| `drop`           | None    | ä¸¢å¼ƒç±»åˆ«     | å›å½’æ¨¡å‹è®¾ `'first'` é¿å…å…±çº¿æ€§ |
| `handle_unknown` | 'error' | æœªçŸ¥ç±»åˆ«     | **ç”Ÿäº§ç¯å¢ƒå¿…é¡»è®¾ `'ignore'`ï¼** |
| `min_frequency`  | None    | åˆå¹¶ç¨€æœ‰ç±»åˆ« | ç±»åˆ«å¤ªå¤šæ—¶è®¾ `5` æˆ– `0.01`      |

> [!] `handle_unknown='error'` é»˜è®¤ä¼šåœ¨é‡åˆ°æ–°ç±»åˆ«æ—¶æŠ¥é”™ï¼ç”Ÿäº§ç¯å¢ƒå¿…é¡»æ”¹æˆ `'ignore'`

---

## 6. ç¼ºå¤±å€¼å¤„ç†

### 6.1 SimpleImputer

```python
SimpleImputer(
    missing_values=np.nan,  # ç¼ºå¤±å€¼æ ‡è®°
    strategy='mean',        # å¡«å……ç­–ç•¥
    fill_value=None,        # constant æ—¶çš„å¡«å……å€¼
    add_indicator=False     # æ˜¯å¦æ·»åŠ ç¼ºå¤±æŒ‡ç¤ºåˆ—
)
```

| strategy å€¼       | è¯´æ˜   | é€‚ç”¨                |
| ----------------- | ------ | ------------------- |
| `'mean'`          | å‡å€¼   | æ•°å€¼ï¼Œæ­£æ€åˆ†å¸ƒ      |
| `'median'`        | ä¸­ä½æ•° | æ•°å€¼ï¼Œæœ‰å¼‚å¸¸å€¼      |
| `'most_frequent'` | ä¼—æ•°   | ç±»åˆ«æˆ–æ•°å€¼          |
| `'constant'`      | å›ºå®šå€¼ | éœ€è¦æŒ‡å®š fill_value |

### 6.2 KNNImputer

```python
KNNImputer(
    n_neighbors=5,    # è¿‘é‚»æ•°
    weights='uniform' # æƒé‡ï¼š'uniform' æˆ– 'distance'
)
```

ç”¨ K è¿‘é‚»çš„å€¼å¡«å……ï¼Œæ•ˆæœé€šå¸¸æ¯”ç®€å•ç­–ç•¥å¥½ï¼Œä½†æ›´æ…¢ã€‚

---

## 7. ColumnTransformer

**ä½œç”¨**: å¯¹ä¸åŒåˆ—åº”ç”¨ä¸åŒé¢„å¤„ç†ï¼ˆ**å®é™…é¡¹ç›®å¿…ç”¨**ï¼‰

```python
ColumnTransformer(
    transformers=[
        ('name1', transformer1, columns1),
        ('name2', transformer2, columns2),
    ],
    remainder='drop',      # æœªæŒ‡å®šçš„åˆ—
    n_jobs=None           # å¹¶è¡Œæ•°
)
```

| å‚æ•°        | é»˜è®¤   | ä½œç”¨       | âš ï¸ ä»€ä¹ˆæ—¶å€™æ”¹            |
| ----------- | ------ | ---------- | ------------------------ |
| `remainder` | `drop` | å‰©ä½™åˆ—å¤„ç† | `'passthrough'` ä¿ç•™åŸæ · |
| `n_jobs`    | None   | å¹¶è¡Œ       | `-1` ç”¨å…¨éƒ¨ CPU          |

### columns æŒ‡å®šæ–¹å¼

```python
# æ–¹å¼1: åˆ—ååˆ—è¡¨
['age', 'income']

# æ–¹å¼2: åˆ—ç´¢å¼•
[0, 1, 2]

# æ–¹å¼3: åˆ—é€‰æ‹©å™¨ï¼ˆæ¨èï¼‰
from sklearn.compose import make_column_selector as selector
selector(dtype_include='number')   # æ‰€æœ‰æ•°å€¼åˆ—
selector(dtype_include='object')   # æ‰€æœ‰å­—ç¬¦ä¸²åˆ—
```

### å®Œæ•´ç¤ºä¾‹

```python
preprocessor = ColumnTransformer([
    ('num', Pipeline([
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler())
    ]), selector(dtype_include='number')),

    ('cat', Pipeline([
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('onehot', OneHotEncoder(handle_unknown='ignore'))
    ]), selector(dtype_include='object'))
])
```

# ç‰¹å¾å·¥ç¨‹

## 1. æ–‡æœ¬ç‰¹å¾æå–

### 1.1 å‘é‡åŒ–å™¨å¯¹æ¯”

| å‘é‡åŒ–å™¨            | è¾“å‡º         | ä¼˜ç‚¹         | ç¼ºç‚¹             | é€‚ç”¨         |
| ------------------- | ------------ | ------------ | ---------------- | ------------ |
| `CountVectorizer`   | è¯é¢‘(æ•´æ•°)   | ç®€å•         | æ— æ³•ä½“ç°è¯é‡è¦æ€§ | æœ´ç´ è´å¶æ–¯   |
| `TfidfVectorizer`   | TF-IDF(æµ®ç‚¹) | ä½“ç°è¯é‡è¦æ€§ | éœ€è¦å…¨éƒ¨æ•°æ®     | é€šç”¨æ–‡æœ¬åˆ†ç±» |
| `HashingVectorizer` | å“ˆå¸Œå€¼       | å†…å­˜é«˜æ•ˆ     | æ— æ³•é€†æ˜ å°„       | å¤§è§„æ¨¡æ•°æ®   |

### 1.2 TfidfVectorizer å‚æ•°è¯¦è§£

```python
TfidfVectorizer(
    max_features=None,      # æœ€å¤šä¿ç•™Nä¸ªè¯
    min_df=1,               # è¯è‡³å°‘å‡ºç°åœ¨Nä¸ªæ–‡æ¡£
    max_df=1.0,             # è¯æœ€å¤šå‡ºç°åœ¨å¤šå°‘æ¯”ä¾‹æ–‡æ¡£
    stop_words=None,        # åœç”¨è¯
    ngram_range=(1, 1),     # n-gramèŒƒå›´
    norm='l2',              # å½’ä¸€åŒ–æ–¹å¼
    sublinear_tf=False      # æ˜¯å¦ç”¨ 1+log(tf)
)
```

| å‚æ•°           | é»˜è®¤   | ä½œç”¨         | âš ï¸ ä»€ä¹ˆæ—¶å€™æ”¹                  |
| -------------- | ------ | ------------ | ------------------------------ |
| `max_features` | None   | é™åˆ¶è¯è¡¨å¤§å° | æ•°æ®é‡å¤§æ—¶è®¾ 5000-10000        |
| `min_df`       | 1      | è¿‡æ»¤ä½é¢‘è¯   | è®¾ `2` æˆ– `0.01` è¿‡æ»¤æ‹¼å†™é”™è¯¯  |
| `max_df`       | 1.0    | è¿‡æ»¤é«˜é¢‘è¯   | è®¾ `0.9` è¿‡æ»¤æ— æ„ä¹‰é«˜é¢‘è¯      |
| `stop_words`   | None   | åœç”¨è¯       | è‹±æ–‡ `'english'`ï¼Œä¸­æ–‡éœ€è‡ªå®šä¹‰ |
| `ngram_range`  | (1, 1) | åªç”¨å•è¯     | åŒ…å«è¯ç»„è®¾ `(1, 2)`            |
| `sublinear_tf` | False  | å¯¹æ•°åŒ–è¯é¢‘   | æŸè¯å‡ºç°æå¤šæ—¶è®¾ True          |

### 1.3 DictVectorizer

å°†å­—å…¸åˆ—è¡¨è½¬ä¸ºç‰¹å¾çŸ©é˜µï¼Œè‡ªåŠ¨ç‹¬çƒ­ç¼–ç å­—ç¬¦ä¸²å€¼ï¼š

```python
DictVectorizer(
    sparse=True,    # è¾“å‡ºç¨€ç–çŸ©é˜µ
    sort=True       # æŒ‰ç‰¹å¾åæ’åº
)
```

---

## 2. å¤šé¡¹å¼ç‰¹å¾

### 2.1 PolynomialFeatures

**ä½œç”¨**: ç”Ÿæˆå¤šé¡¹å¼å’Œäº¤äº’ç‰¹å¾

```python
PolynomialFeatures(
    degree=2,               # æœ€é«˜æ¬¡æ•°
    interaction_only=False, # åªä¿ç•™äº¤äº’é¡¹
    include_bias=True       # åŒ…å«å¸¸æ•°é¡¹1
)
```

| å‚æ•°               | é»˜è®¤  | ä½œç”¨       | âš ï¸ ä»€ä¹ˆæ—¶å€™æ”¹                |
| ------------------ | ----- | ---------- | ---------------------------- |
| `degree`           | 2     | å¤šé¡¹å¼é˜¶æ•° | **é˜¶æ•°é«˜æ˜“è¿‡æ‹Ÿåˆï¼** ä¸€èˆ¬2-3 |
| `interaction_only` | False | åªä¿ç•™ aÃ—b | True ä¸ç”Ÿæˆ aÂ², bÂ²           |
| `include_bias`     | True  | åŒ…å«å¸¸æ•°1  | ä¸æœ‰æˆªè·æ¨¡å‹ä¸€èµ·ç”¨æ—¶è®¾ False |

### 2.2 ç‰¹å¾æ•°é‡å¢é•¿

| åŸç‰¹å¾æ•° | degree=2 | degree=3 |
| -------- | -------- | -------- |
| 2        | 6        | 10       |
| 5        | 21       | 56       |
| 10       | 66       | 286      |

> âš ï¸ **æ³¨æ„**: é«˜æ¬¡å¤šé¡¹å¼ç‰¹å¾æ•°æš´å¢ï¼Œå®¹æ˜“è¿‡æ‹Ÿåˆä¸”è®¡ç®—æ…¢ï¼

---

## 3. ç‰¹å¾é€‰æ‹©

### 3.1 æ–¹æ³•åˆ†ç±»

| ç±»å‹       | æ–¹æ³•                | è¯´æ˜            |
| ---------- | ------------------- | --------------- |
| **è¿‡æ»¤æ³•** | `VarianceThreshold` | ç§»é™¤ä½æ–¹å·®ç‰¹å¾  |
| **è¿‡æ»¤æ³•** | `SelectKBest`       | æŒ‰ç»Ÿè®¡æŒ‡æ ‡é€‰Kä¸ª |
| **åŒ…è£…æ³•** | `RFE`               | é€’å½’æ¶ˆé™¤        |
| **åµŒå…¥æ³•** | `SelectFromModel`   | åŸºäºæ¨¡å‹é‡è¦æ€§  |

### 3.2 VarianceThreshold

```python
VarianceThreshold(threshold=0.0)  # æ–¹å·®é˜ˆå€¼
```

ç§»é™¤æ–¹å·®ä½äºé˜ˆå€¼çš„ç‰¹å¾ã€‚threshold=0 ç§»é™¤å¸¸é‡ç‰¹å¾ã€‚

### 3.3 SelectKBest

```python
SelectKBest(
    score_func=f_classif,  # è¯„åˆ†å‡½æ•°
    k=10                   # é€‰æ‹©Kä¸ª
)
```

| score_func               | é€‚ç”¨ | è¯´æ˜                   |
| ------------------------ | ---- | ---------------------- |
| `f_classif`              | åˆ†ç±» | ANOVA Få€¼              |
| `chi2`                   | åˆ†ç±» | å¡æ–¹æ£€éªŒï¼ˆéœ€éè´Ÿç‰¹å¾ï¼‰ |
| `mutual_info_classif`    | åˆ†ç±» | äº’ä¿¡æ¯                 |
| `f_regression`           | å›å½’ | Få€¼                    |
| `mutual_info_regression` | å›å½’ | äº’ä¿¡æ¯                 |

### 3.4 RFE - é€’å½’ç‰¹å¾æ¶ˆé™¤

```python
RFE(
    estimator,              # åŸºç¡€æ¨¡å‹ï¼ˆéœ€æœ‰coef_æˆ–feature_importances_ï¼‰
    n_features_to_select=None,  # é€‰æ‹©ç‰¹å¾æ•°
    step=1                  # æ¯æ¬¡ç§»é™¤æ•°é‡
)
```

é€æ­¥ç§»é™¤æœ€ä¸é‡è¦çš„ç‰¹å¾ï¼Œç›´åˆ°å‰©ä½™æŒ‡å®šæ•°é‡ã€‚

### 3.5 SelectFromModel

```python
SelectFromModel(
    estimator,            # åŸºç¡€æ¨¡å‹
    threshold='mean',     # é˜ˆå€¼ï¼š'mean', 'median', æ•°å€¼
    prefit=False         # æ¨¡å‹æ˜¯å¦å·²è®­ç»ƒ
)
```

| threshold    | è¯´æ˜               |
| ------------ | ------------------ |
| `'mean'`     | é‡è¦æ€§ > å‡å€¼      |
| `'median'`   | é‡è¦æ€§ > ä¸­ä½æ•°    |
| `'1.5*mean'` | é‡è¦æ€§ > 1.5å€å‡å€¼ |
| æ•°å€¼å¦‚ `0.1` | é‡è¦æ€§ > 0.1       |

### 3.6 é€šç”¨æ–¹æ³•

æ‰€æœ‰é€‰æ‹©å™¨éƒ½æœ‰ï¼š

```python
selector.fit(X, y)
selector.transform(X)
selector.fit_transform(X, y)
selector.get_support()           # è¿”å›å¸ƒå°”æ•°ç»„
selector.get_support(indices=True)  # è¿”å›ç´¢å¼•
```

# Pipeline æµæ°´çº¿

## 1. ä¸ºä»€ä¹ˆç”¨ Pipeline

| é—®é¢˜         | Pipeline è§£å†³æ–¹æ¡ˆ      |
| ------------ | ---------------------- |
| ä»£ç å†—é•¿     | ä¸€è¡Œ fitã€ä¸€è¡Œ predict |
| æ•°æ®æ³„éœ²é£é™© | è‡ªåŠ¨åœ¨æ­£ç¡®çš„æ•°æ®ä¸Š fit |
| äº¤å‰éªŒè¯å¤æ‚ | æ•´ä½“ä½œä¸ºä¸€ä¸ªä¼°è®¡å™¨     |
| éƒ¨ç½²å›°éš¾     | ä¿å­˜ä¸€ä¸ªå¯¹è±¡å³å¯       |

---

## 2. åˆ›å»º Pipeline

### 2.1 æ˜¾å¼å‘½å

```python
from sklearn.pipeline import Pipeline

pipe = Pipeline([
    ('scaler', StandardScaler()),    # (åç§°, è½¬æ¢å™¨)
    ('pca', PCA(n_components=2)),
    ('svm', SVC())                   # æœ€åä¸€æ­¥é€šå¸¸æ˜¯æ¨¡å‹
])
```

### 2.2 è‡ªåŠ¨å‘½å

```python
from sklearn.pipeline import make_pipeline

pipe = make_pipeline(
    StandardScaler(),
    PCA(n_components=2),
    SVC()
)
# è‡ªåŠ¨å‘½å: standardscaler, pca, svc
```

### 2.3 ä½¿ç”¨

```python
pipe.fit(X_train, y_train)
pipe.predict(X_test)
pipe.score(X_test, y_test)
```

---

## 3. å‚æ•°è®¿é—®

### 3.1 è®¿é—®æ­¥éª¤

```python
pipe.steps              # [(name, estimator), ...]
pipe.named_steps        # {'name': estimator, ...}
pipe.named_steps['pca'] # é€šè¿‡åç§°
pipe[0]                 # é€šè¿‡ç´¢å¼•
pipe[-1]                # æœ€åä¸€æ­¥
pipe[:2]                # åˆ‡ç‰‡ï¼ˆè¿”å›æ–° Pipelineï¼‰
```

### 3.2 è®¾ç½®å‚æ•°

æ ¼å¼: `æ­¥éª¤å__å‚æ•°å`

```python
pipe.set_params(
    pca__n_components=3,
    svm__C=10,
    svm__kernel='rbf'
)

# è·å–å‚æ•°
pipe.get_params()
```

### 3.3 åµŒå¥— Pipeline å‚æ•°

```python
# preprocessor æ˜¯ ColumnTransformer
# num æ˜¯å…¶ä¸­ä¸€ä¸ªè½¬æ¢å™¨
# imputer æ˜¯ num Pipeline ä¸­çš„æ­¥éª¤
pipe.set_params(preprocessor__num__imputer__strategy='mean')
```

---

## 4. ä¸ GridSearchCV ç»“åˆ

```python
param_grid = {
    'pca__n_components': [2, 3, 4],
    'svm__C': [0.1, 1, 10],
    'svm__kernel': ['linear', 'rbf']
}

grid = GridSearchCV(pipe, param_grid, cv=5)
grid.fit(X_train, y_train)

print(grid.best_params_)
print(grid.best_score_)
```

### åŠ¨æ€è·³è¿‡æ­¥éª¤

```python
param_grid = [
    # ä¸ç”¨ PCA
    {'pca': ['passthrough'], 'svm__C': [1, 10]},
    # ç”¨ PCA
    {'pca__n_components': [2, 3], 'svm__C': [1, 10]}
]
```

---

## 5. ColumnTransformer

å¯¹ä¸åŒåˆ—åº”ç”¨ä¸åŒé¢„å¤„ç†ï¼š

```python
from sklearn.compose import ColumnTransformer, make_column_selector as selector

preprocessor = ColumnTransformer([
    ('num', numeric_pipeline, ['age', 'income']),
    ('cat', categorical_pipeline, ['gender', 'city'])
])
```

### 5.1 å‚æ•°è¯¦è§£

```python
ColumnTransformer(
    transformers=[...],
    remainder='drop',      # å‰©ä½™åˆ—å¤„ç†
    sparse_threshold=0.3,
    n_jobs=None
)
```

| å‚æ•°        | é»˜è®¤   | é€‰é¡¹                                |
| ----------- | ------ | ----------------------------------- |
| `remainder` | 'drop' | `'drop'` ä¸¢å¼ƒ, `'passthrough'` ä¿ç•™ |
| `n_jobs`    | None   | `-1` å¹¶è¡ŒåŠ é€Ÿ                       |

### 5.2 åˆ—é€‰æ‹©æ–¹å¼

```python
# åˆ—ååˆ—è¡¨
['age', 'income']

# åˆ—ç´¢å¼•
[0, 1, 2]

# è‡ªåŠ¨é€‰æ‹©å™¨
selector(dtype_include='number')    # æ•°å€¼åˆ—
selector(dtype_include='object')    # å­—ç¬¦ä¸²åˆ—
selector(dtype_exclude='datetime')  # æ’é™¤æ—¥æœŸ
```

### 5.3 å®Œæ•´ç¤ºä¾‹

```python
full_pipeline = Pipeline([
    ('preprocessor', ColumnTransformer([
        ('num', Pipeline([
            ('imputer', SimpleImputer(strategy='median')),
            ('scaler', StandardScaler())
        ]), selector(dtype_include='number')),

        ('cat', Pipeline([
            ('imputer', SimpleImputer(strategy='most_frequent')),
            ('onehot', OneHotEncoder(handle_unknown='ignore'))
        ]), selector(dtype_include='object'))
    ])),
    ('classifier', LogisticRegression())
])
```

---

## 6. TransformedTargetRegressor

å¯¹ç›®æ ‡å˜é‡ y è¿›è¡Œå˜æ¢ï¼š

```python
from sklearn.compose import TransformedTargetRegressor

ttr = TransformedTargetRegressor(
    regressor=LinearRegression(),
    func=np.log1p,           # y -> log(1+y)
    inverse_func=np.expm1    # é€†å˜æ¢
)
```

| å‚æ•°           | è¯´æ˜                    |
| -------------- | ----------------------- |
| `func`         | å˜æ¢å‡½æ•°                |
| `inverse_func` | é€†å˜æ¢å‡½æ•°              |
| `transformer`  | ä¹Ÿå¯ä¼ å…¥ sklearn è½¬æ¢å™¨ |

---

## 7. Pipeline ç¼“å­˜

```python
from tempfile import mkdtemp

pipe = Pipeline([...], memory=mkdtemp())
```

ç¼“å­˜ä¸­é—´æ­¥éª¤ç»“æœï¼ŒGridSearchCV æ—¶é¿å…é‡å¤è®¡ç®—ã€‚

# æ¨¡å‹é€‰æ‹©ä¸è°ƒå‚

---

## 1. äº¤å‰éªŒè¯

### 1.1 cross_val_score

```python
cross_val_score(
    estimator,
    X, y,
    cv=5,              # æŠ˜æ•°
    scoring='accuracy' # è¯„åˆ†æŒ‡æ ‡
)
```

è¿”å›æ¯æŠ˜çš„å¾—åˆ†æ•°ç»„ã€‚

### äº¤å‰éªŒè¯å¯è§†åŒ–

ä¸‹å›¾å±•ç¤ºäº† 5 æŠ˜äº¤å‰éªŒè¯çš„å„æŠ˜å¾—åˆ†ï¼š

![05_cross_val](https://img.yumeko.site/file/articles/sklearn/05_cross_val.png)

### 1.2 cross_validate

```python
cross_validate(
    estimator, X, y,
    cv=5,
    scoring=['accuracy', 'f1'],  # å¤šä¸ªæŒ‡æ ‡
    return_train_score=True,     # è¿”å›è®­ç»ƒåˆ†æ•°
    return_estimator=True        # è¿”å›è®­ç»ƒå¥½çš„æ¨¡å‹
)
```

è¿”å›å­—å…¸ï¼ŒåŒ…å« `test_accuracy`, `train_accuracy`, `fit_time` ç­‰ã€‚

### 1.3 å¸¸ç”¨è¯„åˆ†æŒ‡æ ‡

| ç±»å‹ | scoring                    | è¯´æ˜         |
| ---- | -------------------------- | ------------ |
| åˆ†ç±» | `'accuracy'`               | å‡†ç¡®ç‡       |
| åˆ†ç±» | `'f1'`                     | F1ï¼ˆäºŒåˆ†ç±»ï¼‰ |
| åˆ†ç±» | `'f1_macro'`               | F1 å®å¹³å‡    |
| åˆ†ç±» | `'roc_auc'`                | ROC AUC      |
| å›å½’ | `'r2'`                     | RÂ²           |
| å›å½’ | `'neg_mean_squared_error'` | è´ŸMSE        |

---

## 2. åˆ’åˆ†ç­–ç•¥

| åˆ’åˆ†å™¨            | é€‚ç”¨åœºæ™¯             |
| ----------------- | -------------------- |
| `KFold`           | é€šç”¨                 |
| `StratifiedKFold` | åˆ†ç±»ï¼ˆä¿æŒç±»åˆ«æ¯”ä¾‹ï¼‰ |
| `ShuffleSplit`    | å¤§æ•°æ®é›†             |
| `TimeSeriesSplit` | æ—¶é—´åºåˆ—             |
| `LeaveOneOut`     | å°æ•°æ®é›†             |

### 2.1 å‚æ•°è¯¦è§£

```python
KFold(
    n_splits=5,      # æŠ˜æ•°
    shuffle=False,   # æ˜¯å¦æ‰“ä¹±
    random_state=None
)

StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

TimeSeriesSplit(n_splits=5)  # æ—  shuffle
```

> [!WARNING] æ³¨æ„
>  **åˆ†ç±»é—®é¢˜å¿…é¡»ç”¨ StratifiedKFold**ï¼Œå¦åˆ™æŸæŠ˜å¯èƒ½ç¼ºå°‘æŸç±»åˆ«ï¼

---

## 3. ç½‘æ ¼æœç´¢

### 3.1 GridSearchCV å‚æ•°

```python
GridSearchCV(
    estimator,
    param_grid,           # å‚æ•°ç½‘æ ¼
    scoring=None,         # è¯„åˆ†æŒ‡æ ‡
    n_jobs=None,          # å¹¶è¡Œæ•°
    refit=True,           # ç”¨æœ€ä½³å‚æ•°é‡è®­ç»ƒ
    cv=5,                 # äº¤å‰éªŒè¯
    verbose=0,            # è¾“å‡ºè¯¦ç»†åº¦
    return_train_score=False
)
```

| å‚æ•°      | é»˜è®¤ | âš ï¸ ä»€ä¹ˆæ—¶å€™æ”¹                 |
| --------- | ---- | ----------------------------- |
| `scoring` | None | å¿…é¡»æŒ‡å®šï¼åˆ†ç±»ç”¨ `'accuracy'` |
| `n_jobs`  | None | è®¾ `-1` ç”¨å…¨éƒ¨CPU             |
| `cv`      | 5    | å°æ•°æ®ç”¨ 3 æˆ– 10              |
| `verbose` | 0    | çœ‹è¿›åº¦è®¾ 1 æˆ– 2               |
| `refit`   | True | åªæ‰¾å‚æ•°ä¸è®­ç»ƒè®¾ False        |

### 3.2 param_grid æ ¼å¼

```python
# æ–¹å¼1: å­—å…¸
param_grid = {
    'C': [0.1, 1, 10],
    'kernel': ['linear', 'rbf']
}

# æ–¹å¼2: å­—å…¸åˆ—è¡¨ï¼ˆä¸åŒç»„åˆï¼‰
param_grid = [
    {'kernel': ['linear'], 'C': [1, 10]},
    {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.1, 1]}
]
```

### 3.3 ç»“æœè®¿é—®

```python
grid.best_params_      # æœ€ä½³å‚æ•°
grid.best_score_       # æœ€ä½³äº¤å‰éªŒè¯åˆ†æ•°
grid.best_estimator_   # æœ€ä½³æ¨¡å‹ï¼ˆå·²è®­ç»ƒï¼‰
grid.cv_results_       # è¯¦ç»†ç»“æœå­—å…¸
```

---

## 4. éšæœºæœç´¢

### 4.1 RandomizedSearchCV

```python
from scipy.stats import uniform, loguniform

RandomizedSearchCV(
    estimator,
    param_distributions,  # å‚æ•°åˆ†å¸ƒ
    n_iter=10,           # é‡‡æ ·æ¬¡æ•°
    scoring=None,
    n_jobs=None,
    cv=5,
    random_state=None
)
```

| å‚æ•°                  | è¯´æ˜                             |
| --------------------- | -------------------------------- |
| `n_iter`              | é‡‡æ ·ç»„åˆæ•°ï¼Œè¶Šå¤§è¶Šå¯èƒ½æ‰¾åˆ°å¥½å‚æ•° |
| `param_distributions` | å¯ä»¥æ˜¯åˆ—è¡¨æˆ–åˆ†å¸ƒå¯¹è±¡             |

### 4.2 å‚æ•°åˆ†å¸ƒ

```python
from scipy.stats import uniform, loguniform, randint

param_distributions = {
    'C': loguniform(0.01, 100),    # å¯¹æ•°å‡åŒ€åˆ†å¸ƒ
    'gamma': loguniform(1e-4, 1),
    'kernel': ['rbf', 'linear'],   # ç¦»æ•£å€¼ç”¨åˆ—è¡¨
    'n_estimators': randint(50, 200)  # æ•´æ•°å‡åŒ€åˆ†å¸ƒ
}
```

### 4.3 Grid vs Random

|              | GridSearchCV | RandomizedSearchCV |
| ------------ | ------------ | ------------------ |
| æœç´¢æ–¹å¼     | éå†æ‰€æœ‰ç»„åˆ | éšæœºé‡‡æ ·           |
| å‚æ•°å¤šæ—¶     | å¾ˆæ…¢         | å¿«                 |
| ä¿è¯æ‰¾åˆ°æœ€ä¼˜ | âœ…           | âŒ ä½†é€šå¸¸å¤Ÿå¥½      |
| é€‚ç”¨         | å‚æ•°å°‘       | å‚æ•°å¤š             |

---

## 5. å­¦ä¹ æ›²çº¿

è¯Šæ–­è¿‡æ‹Ÿåˆ/æ¬ æ‹Ÿåˆï¼š

```python
learning_curve(
    estimator, X, y,
    cv=5,
    train_sizes=np.linspace(0.1, 1.0, 10),
    scoring='accuracy'
)
```

è¿”å›: `train_sizes, train_scores, test_scores`

### å­¦ä¹ æ›²çº¿å¯è§†åŒ–

ä¸‹å›¾å±•ç¤ºäº†æ¨¡å‹çš„å­¦ä¹ æ›²çº¿ï¼š

![05_learning_curve](https://img.yumeko.site/file/articles/sklearn/05_learning_curve.png)

### è§£è¯»

| ç°è±¡           | è¯Šæ–­   | è§£å†³                 |
| -------------- | ------ | -------------------- |
| è®­ç»ƒé«˜ã€æµ‹è¯•ä½ | è¿‡æ‹Ÿåˆ | æ›´å¤šæ•°æ®ã€æ­£åˆ™åŒ–     |
| ä¸¤è€…éƒ½ä½       | æ¬ æ‹Ÿåˆ | æ›´å¤æ‚æ¨¡å‹ã€æ›´å¤šç‰¹å¾ |
| ä¸¤è€…éƒ½é«˜ä¸”æ¥è¿‘ | ç†æƒ³   | ä¿æŒ                 |

---

## 6. éªŒè¯æ›²çº¿

åˆ†æå•ä¸ªå‚æ•°çš„å½±å“ï¼š

```python
validation_curve(
    estimator, X, y,
    param_name='C',
    param_range=np.logspace(-3, 3, 7),
    cv=5
)
```

è¿”å›: `train_scores, test_scores`

### éªŒè¯æ›²çº¿å¯è§†åŒ–

ä¸‹å›¾å±•ç¤ºäº† SVC å‚æ•° C çš„éªŒè¯æ›²çº¿ï¼š

![05_validation_curve](https://img.yumeko.site/file/articles/sklearn/05_validation_curve.png)

# è¯„ä¼°æŒ‡æ ‡ä¸å¯è§†åŒ–

---

## 1. åˆ†ç±»æŒ‡æ ‡

### 1.1 åŸºç¡€æŒ‡æ ‡

| æŒ‡æ ‡      | å…¬å¼                            | é€‚ç”¨åœºæ™¯           |
| --------- | ------------------------------- | ------------------ |
| Accuracy  | $\frac{TP+TN}{TP+TN+FP+FN}$     | ç±»åˆ«å¹³è¡¡           |
| Precision | $\frac{TP}{TP+FP}$              | å…³æ³¨å‡æ­£ä¾‹ä»£ä»·     |
| Recall    | $\frac{TP}{TP+FN}$              | å…³æ³¨å‡è´Ÿä¾‹ä»£ä»·     |
| F1        | $\frac{2 \cdot P \cdot R}{P+R}$ | å¹³è¡¡ç²¾ç¡®ç‡å’Œå¬å›ç‡ |

### åˆ†ç±»æŒ‡æ ‡å¯è§†åŒ–

ä¸‹å›¾å±•ç¤ºäº†ä¹¾è…˜ç™Œæ•°æ®é›†ä¸Šçš„åˆ†ç±»æŒ‡æ ‡ï¼š

![06_classification_metrics](https://img.yumeko.site/file/articles/sklearn/06_classification_metrics.png)

```python
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

accuracy_score(y_true, y_pred)
precision_score(y_true, y_pred)
recall_score(y_true, y_pred)
f1_score(y_true, y_pred)
```

### 1.2 å¤šåˆ†ç±» average å‚æ•°

```python
f1_score(y_true, y_pred, average='macro')
```

| average      | è¯´æ˜                         |
| ------------ | ---------------------------- |
| `'binary'`   | äºŒåˆ†ç±»é»˜è®¤ï¼Œåªç®—æ­£ç±»         |
| `'micro'`    | å…¨å±€è®¡ç®— TP/FP/FN            |
| `'macro'`    | å„ç±»åˆ«å¹³å‡ï¼ˆä¸è€ƒè™‘ç±»åˆ«å¤§å°ï¼‰ |
| `'weighted'` | æŒ‰ç±»åˆ«æ ·æœ¬æ•°åŠ æƒå¹³å‡         |

### 1.3 ROC AUC

**ROC æ›²çº¿**: ä¸åŒé˜ˆå€¼ä¸‹ TPR (å¬å›ç‡) ä¸ FPR (å‡æ­£è¯†ç‡) çš„æ›²çº¿ã€‚

- **TPR (True Positive Rate)**: $TPR = \frac{TP}{TP+FN}$
- **FPR (False Positive Rate)**: $FPR = \frac{FP}{FP+TN}$
- **AUC**: æ›²çº¿ä¸‹é¢ç§¯ï¼Œ$1$ ä¸ºå®Œç¾ï¼Œ$0.5$ ä¸ºéšæœº

### ROC å’Œ PR æ›²çº¿å¯è§†åŒ–

ä¸‹å›¾å±•ç¤ºäº† ROC æ›²çº¿å’Œ Precision-Recall æ›²çº¿ï¼š

![06_roc_pr](https://img.yumeko.site/file/articles/sklearn/06_roc_pr.png)

```python
roc_auc_score(
    y_true,
    y_score,           # predict_proba çš„ç»“æœ
    multi_class='ovr'  # å¤šåˆ†ç±»: 'ovr' æˆ– 'ovo'
)
```

### 1.4 classification_report

```python
print(classification_report(y_true, y_pred, target_names=['è´Ÿç±»', 'æ­£ç±»']))
```

è¾“å‡ºç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1ã€æ”¯æŒåº¦çš„å®Œæ•´æŠ¥å‘Šã€‚

---

## 2. å›å½’æŒ‡æ ‡

| æŒ‡æ ‡  | å…¬å¼                             | è¯´æ˜                       |
| ----- | -------------------------------- | -------------------------- |
| $R^2$ | $1 - \frac{SS_{res}}{SS_{tot}}$  | å†³å®šç³»æ•°ï¼Œ$1$ æœ€å¥½         |
| MSE   | $\frac{1}{n}\sum(y - \hat{y})^2$ | å‡æ–¹è¯¯å·®ï¼Œå¯¹å¤§è¯¯å·®æ•æ„Ÿ     |
| RMSE  | $\sqrt{MSE}$                     | å‡æ–¹æ ¹è¯¯å·®                 |
| MAE   | $\frac{1}{n}\sum y - \hat{y}$    | å¹³å‡ç»å¯¹è¯¯å·®ï¼Œå¯¹å¼‚å¸¸å€¼é²æ£’ |

### å›å½’æŒ‡æ ‡å¯è§†åŒ–

ä¸‹å›¾å±•ç¤ºäº†å›å½’æ¨¡å‹çš„é¢„æµ‹ vs çœŸå®å€¼å’Œæ®‹å·®åˆ†å¸ƒï¼š

![06_regression_metrics](<https://img.yumeko.site/file/articles/sklearn/06_regression_metrics(1).png>)

```python
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

r2_score(y_true, y_pred)
mean_squared_error(y_true, y_pred)
mean_absolute_error(y_true, y_pred)
```

---

## 3. å¯è§†åŒ–å·¥å…·

### æ··æ·†çŸ©é˜µå¯è§†åŒ–

ä¸‹å›¾å±•ç¤ºäº†æ··æ·†çŸ©é˜µåŠå…¶è§£è¯»ï¼š

![06_confusion_matrix](<https://img.yumeko.site/file/articles/sklearn/06_confusion_matrix(1).png>)

### 3.1 ConfusionMatrixDisplay

```python
from sklearn.metrics import ConfusionMatrixDisplay

# æ–¹å¼1: ä»é¢„æµ‹ç»“æœ
ConfusionMatrixDisplay.from_predictions(y_true, y_pred)

# æ–¹å¼2: ä»ä¼°è®¡å™¨
ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)

# å‚æ•°
ConfusionMatrixDisplay.from_predictions(
    y_true, y_pred,
    display_labels=['è´Ÿ', 'æ­£'],  # æ ‡ç­¾
    normalize='true',             # å½’ä¸€åŒ–: 'true', 'pred', 'all'
    cmap='Blues'                  # é¢œè‰²
)
```

### 3.2 RocCurveDisplay

```python
from sklearn.metrics import RocCurveDisplay

RocCurveDisplay.from_estimator(model, X_test, y_test)
RocCurveDisplay.from_predictions(y_true, y_proba)
```

### 3.3 PrecisionRecallDisplay

```python
from sklearn.metrics import PrecisionRecallDisplay

PrecisionRecallDisplay.from_estimator(model, X_test, y_test)
PrecisionRecallDisplay.from_predictions(y_true, y_proba)
```

### 3.4 plot_tree

```python
from sklearn.tree import plot_tree

plot_tree(
    decision_tree,
    feature_names=feature_names,
    class_names=class_names,
    filled=True,
    rounded=True
)
```

### 3.5 DecisionBoundaryDisplay

```python
from sklearn.inspection import DecisionBoundaryDisplay

DecisionBoundaryDisplay.from_estimator(
    model, X,  # X å¿…é¡»æ˜¯ 2 ç»´
    response_method='predict',  # 'predict' æˆ– 'predict_proba'
    alpha=0.5
)
```

---

## 4. è‡ªå®šä¹‰è¯„åˆ†

### 4.1 make_scorer

```python
from sklearn.metrics import make_scorer

def my_score(y_true, y_pred):
    # è¿”å›æ•°å€¼ï¼Œè¶Šå¤§è¶Šå¥½
    return ...

my_scorer = make_scorer(my_score)

# ä½¿ç”¨
cross_val_score(model, X, y, scoring=my_scorer)
GridSearchCV(model, params, scoring=my_scorer)
```

### 4.2 å‚æ•°

```python
make_scorer(
    score_func,
    greater_is_better=True,  # False è¡¨ç¤ºè¶Šå°è¶Šå¥½
    **kwargs                 # ä¼ ç»™ score_func çš„é¢å¤–å‚æ•°
)
```

### 4.3 ç¤ºä¾‹

```python
from sklearn.metrics import fbeta_score

# F2 åˆ†æ•°ï¼ˆæ›´é‡è§†å¬å›ç‡ï¼‰
f2_scorer = make_scorer(fbeta_score, beta=2)
```

# å¸¸ç”¨æ¨¡å‹é€ŸæŸ¥

---

## 1. çº¿æ€§æ¨¡å‹

### 1.1 å›å½’

| æ¨¡å‹               | æ­£åˆ™åŒ–               | æŸå¤±å‡½æ•°                                 |
| ------------------ | -------------------- | ---------------------------------------- |
| `LinearRegression` | æ—                    | $\|y - X\beta\|^2$                       |
| `Ridge`            | L2 ($\|\beta\|_2^2$) | $\|y - X\beta\|^2 + \alpha\|\beta\|_2^2$ |
| `Lasso`            | L1 ($\|\beta\|_1$)   | $\|y - X\beta\|^2 + \alpha\|\beta\|_1$   |
| `ElasticNet`       | L1+L2                | æ··åˆæ­£åˆ™åŒ–                               |

### çº¿æ€§æ¨¡å‹å¯è§†åŒ–

ä¸‹å›¾å±•ç¤ºäº†ä¸åŒæ­£åˆ™åŒ–æ–¹æ³•çš„ç³»æ•°å¯¹æ¯”ï¼š

![07_linear_models](https://img.yumeko.site/file/articles/sklearn/07_linear_models.png)

```python
Ridge(alpha=1.0)  # alpha è¶Šå¤§ï¼Œæ­£åˆ™åŒ–è¶Šå¼º
Lasso(alpha=0.1)  # ä¼šäº§ç”Ÿç¨€ç–ç³»æ•°ï¼ˆç‰¹å¾é€‰æ‹©ï¼‰
```

### 1.2 LogisticRegression

```python
LogisticRegression(
    penalty='l2',           # æ­£åˆ™åŒ–: 'l1', 'l2', 'elasticnet', None
    C=1.0,                  # æ­£åˆ™åŒ–å¼ºåº¦çš„å€’æ•°ï¼ˆCå¤§=å¼±æ­£åˆ™åŒ–ï¼‰
    solver='lbfgs',         # ä¼˜åŒ–å™¨
    max_iter=100,           # æœ€å¤§è¿­ä»£
    class_weight=None,      # ç±»åˆ«æƒé‡
    multi_class='auto'      # å¤šåˆ†ç±»ç­–ç•¥
)
```

| å‚æ•°           | å€¼            | è¯´æ˜                              |
| -------------- | ------------- | --------------------------------- |
| `C`            | 1.0           | **Cè¶Šå¤§æ­£åˆ™åŒ–è¶Šå¼±**ï¼Œè¿‡æ‹Ÿåˆæ—¶å‡å° |
| `class_weight` | `'balanced'`  | ç±»åˆ«ä¸å¹³è¡¡æ—¶ä½¿ç”¨                  |
| `solver`       | `'liblinear'` | L1æ­£åˆ™åŒ–å¿…é¡»ç”¨è¿™ä¸ª                |

---

## 2. æ ‘æ¨¡å‹ä¸é›†æˆ

### 2.1 DecisionTreeClassifier

```python
DecisionTreeClassifier(
    max_depth=None,         # æœ€å¤§æ·±åº¦
    min_samples_split=2,    # åˆ†è£‚æœ€å°æ ·æœ¬
    min_samples_leaf=1,     # å¶èŠ‚ç‚¹æœ€å°æ ·æœ¬
    criterion='gini',       # 'gini' æˆ– 'entropy'
    class_weight=None
)
```

### 2.2 RandomForestClassifier

```python
RandomForestClassifier(
    n_estimators=100,       # æ ‘çš„æ•°é‡
    max_depth=None,         # æ ‘çš„æ·±åº¦
    max_features='sqrt',    # åˆ†è£‚æ—¶è€ƒè™‘çš„ç‰¹å¾æ•°
    bootstrap=True,         # æœ‰æ”¾å›é‡‡æ ·
    oob_score=False,        # è¢‹å¤–è¯„ä¼°
    n_jobs=None,            # å¹¶è¡Œ
    class_weight=None
)
```

| å‚æ•°           | å»ºè®®å€¼  | è¯´æ˜               |
| -------------- | ------- | ------------------ |
| `n_estimators` | 100-500 | è¶Šå¤šè¶Šå¥½ä½†è¶Šæ…¢     |
| `max_depth`    | 5-20    | è¿‡æ‹Ÿåˆæ—¶è®¾ç½®       |
| `n_jobs`       | -1      | å¹¶è¡ŒåŠ é€Ÿ           |
| `oob_score`    | True    | å…äº¤å‰éªŒè¯å¿«é€Ÿè¯„ä¼° |

### 2.3 GradientBoostingClassifier

```python
GradientBoostingClassifier(
    n_estimators=100,
    learning_rate=0.1,      # å­¦ä¹ ç‡
    max_depth=3,            # é€šå¸¸è®¾å°ä¸€äº›
    subsample=1.0           # æ ·æœ¬é‡‡æ ·æ¯”ä¾‹
)
```

> ğŸ’¡ **learning_rate å’Œ n_estimators è¦ä¸€èµ·è°ƒ**ï¼šlearning_rate å°æ—¶éœ€è¦æ›´å¤š n_estimators

---

## 3. SVM

### 3.1 SVC

```python
SVC(
    C=1.0,              # è½¯é—´éš”ï¼ŒCå¤§=ç¡¬é—´éš”
    kernel='rbf',       # æ ¸å‡½æ•°
    gamma='scale',      # æ ¸ç³»æ•°
    class_weight=None,
    probability=False   # å¼€å¯åå¯ç”¨ predict_proba
)
```

| kernel     | é€‚ç”¨               |
| ---------- | ------------------ |
| `'linear'` | çº¿æ€§å¯åˆ†ï¼Œé«˜ç»´æ•°æ® |
| `'rbf'`    | é€šç”¨ï¼Œé»˜è®¤é€‰æ‹©     |
| `'poly'`   | å¤šé¡¹å¼æ ¸           |

| å‚æ•°    | è¯´æ˜                           |
| ------- | ------------------------------ |
| `C`     | å¤§=æ‹Ÿåˆè®­ç»ƒæ•°æ®ï¼Œå°=æ›´å¹³æ»‘è¾¹ç•Œ |
| `gamma` | å¤§=æ›´å¤æ‚è¾¹ç•Œï¼Œå°=æ›´å¹³æ»‘       |

### SVM å†³ç­–è¾¹ç•Œå¯è§†åŒ–

ä¸‹å›¾å±•ç¤ºäº†ä¸åŒæ ¸å‡½æ•°çš„å†³ç­–è¾¹ç•Œï¼š

![07_svm](https://img.yumeko.site/file/articles/sklearn/07_svm.png)

> âš ï¸ **SVM å¿…é¡»æ ‡å‡†åŒ–æ•°æ®ï¼**

---

## 4. æœ´ç´ è´å¶æ–¯

| æ¨¡å‹            | é€‚ç”¨æ•°æ®          |
| --------------- | ----------------- |
| `GaussianNB`    | è¿ç»­ç‰¹å¾          |
| `MultinomialNB` | è®¡æ•°/è¯é¢‘ï¼ˆéè´Ÿï¼‰ |
| `BernoulliNB`   | äºŒå€¼ç‰¹å¾          |

```python
GaussianNB()  # æ— è¶…å‚æ•°

MultinomialNB(alpha=1.0)  # alpha = æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘

BernoulliNB(binarize=0.0)  # äºŒå€¼åŒ–é˜ˆå€¼
```

---

## 5. èšç±»

### 5.1 KMeans

```python
KMeans(
    n_clusters=8,       # èšç±»æ•°
    init='k-means++',   # åˆå§‹åŒ–
    n_init=10,          # è¿è¡Œæ¬¡æ•°
    max_iter=300
)
```

### 5.2 DBSCAN

```python
DBSCAN(
    eps=0.5,            # é‚»åŸŸåŠå¾„
    min_samples=5       # æ ¸å¿ƒç‚¹æœ€å°æ ·æœ¬æ•°
)
```

| å‚æ•°             | æ•ˆæœ                   |
| ---------------- | ---------------------- |
| `eps` å¤§         | æ›´å¤§çš„ç°‡               |
| `min_samples` å¤§ | æ›´å°‘çš„å™ªå£°ç‚¹ï¼Œæ›´å°çš„ç°‡ |

### èšç±»ç®—æ³•å¯è§†åŒ–

ä¸‹å›¾å±•ç¤ºäº† KMeans å’Œ DBSCAN çš„èšç±»ç»“æœå¯¹æ¯”ï¼š

![07_clustering](https://img.yumeko.site/file/articles/sklearn/07_clustering.png)

---

## 6. é™ç»´

### 6.1 PCA

```python
PCA(
    n_components=2,     # ä¿ç•™ç»„ä»¶æ•°ï¼Œå¯ä»¥æ˜¯æ•´æ•°æˆ–æ¯”ä¾‹å¦‚ 0.95
    svd_solver='auto'
)
```

### 6.2 t-SNE

```python
TSNE(
    n_components=2,
    perplexity=30,      # å›°æƒ‘åº¦ï¼Œ5-50
    learning_rate='auto'
)
```

> âš ï¸ **t-SNE åªèƒ½ fit_transformï¼Œä¸èƒ½ transform æ–°æ•°æ®ï¼**

### é™ç»´ç»“æœå¯è§†åŒ–

ä¸‹å›¾å±•ç¤ºäº† PCA å’Œ t-SNE çš„é™ç»´ç»“æœå¯¹æ¯”ï¼š

![07_dimensionality_reduction](https://img.yumeko.site/file/articles/sklearn/07_dimensionality_reduction.png)

# å®ç”¨æŠ€å·§
---

## 1. æ¨¡å‹å…‹éš†

```python
from sklearn.base import clone

rf_clone = clone(rf)  # å¤åˆ¶å‚æ•°ï¼Œä¸å¤åˆ¶è®­ç»ƒçŠ¶æ€
```

ç”¨é€”ï¼šéœ€è¦ç”¨ç›¸åŒé…ç½®è®­ç»ƒå¤šä¸ªç‹¬ç«‹æ¨¡å‹æ—¶ã€‚

---

## 2. ç±»åˆ«ä¸å¹³è¡¡

### 2.1 class_weight å‚æ•°

```python
LogisticRegression(class_weight='balanced')
RandomForestClassifier(class_weight='balanced')
SVC(class_weight='balanced')
```

| å€¼              | è¯´æ˜                   |
| --------------- | ---------------------- |
| `None`          | é»˜è®¤ï¼Œæ‰€æœ‰ç±»åˆ«æƒé‡=1   |
| `'balanced'`    | è‡ªåŠ¨è®¡ç®—ï¼Œå°‘æ•°ç±»æƒé‡é«˜ |
| `{0: 1, 1: 10}` | æ‰‹åŠ¨æŒ‡å®šå„ç±»åˆ«æƒé‡     |

### 2.2 è®¡ç®—æƒé‡

```python
from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight

# ç±»åˆ«æƒé‡
class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)

# æ ·æœ¬æƒé‡
sample_weights = compute_sample_weight('balanced', y)
```

### 2.3 ä½•æ—¶ä½¿ç”¨

| æ¯”ä¾‹  | å»ºè®®                    |
| ----- | ----------------------- |
| 2:1   | å¯ä»¥å°è¯• balanced       |
| 10:1  | å»ºè®®ä½¿ç”¨ balanced       |
| 100:1 | å¿…é¡»ä½¿ç”¨ + è€ƒè™‘å…¶ä»–æ–¹æ³• |

---

## 3. è‡ªå®šä¹‰ä¼°è®¡å™¨

### 3.1 è‡ªå®šä¹‰è½¬æ¢å™¨

```python
from sklearn.base import BaseEstimator, TransformerMixin

class MyTransformer(BaseEstimator, TransformerMixin):
    def __init__(self, param1=1):
        self.param1 = param1

    def fit(self, X, y=None):
        # å­¦ä¹ å‚æ•°ï¼ˆå¯é€‰ï¼‰
        self.learned_param_ = X.mean()  # ä»¥ä¸‹åˆ’çº¿ç»“å°¾
        return self

    def transform(self, X):
        return X - self.learned_param_
```

### 3.2 è‡ªå®šä¹‰åˆ†ç±»å™¨

```python
from sklearn.base import BaseEstimator, ClassifierMixin

class MyClassifier(BaseEstimator, ClassifierMixin):
    def fit(self, X, y):
        self.classes_ = np.unique(y)
        # è®­ç»ƒé€»è¾‘
        return self

    def predict(self, X):
        # é¢„æµ‹é€»è¾‘
        return predictions
```

### 3.3 è§„åˆ™

1. `__init__` åªä¿å­˜å‚æ•°ï¼Œä¸åšè®¡ç®—
2. å­¦ä¹ åˆ°çš„å±æ€§ä»¥ `_` ç»“å°¾ï¼ˆå¦‚ `classes_`ï¼‰
3. `fit` å¿…é¡»è¿”å› `self`

---

## 4. æ¨¡å‹æŒä¹…åŒ–

### 4.1 joblib vs pickle

|        | joblib         | pickle |
| ------ | -------------- | ------ |
| æ¨èåº¦ | âœ… sklearnæ¨è | å¯ç”¨   |
| å¤§æ•°ç»„ | æ›´å¿«           | è¾ƒæ…¢   |
| å‹ç¼©   | æ”¯æŒ           | ä¸æ”¯æŒ |

### 4.2 ä½¿ç”¨ joblib

```python
import joblib

# ä¿å­˜
joblib.dump(model, 'model.joblib')

# åŠ è½½
model = joblib.load('model.joblib')

# å‹ç¼©ä¿å­˜ï¼ˆ1-9çº§ï¼‰
joblib.dump(model, 'model.joblib', compress=3)
```

### 4.3 ä¿å­˜æ•´ä¸ª Pipeline

```python
joblib.dump(pipeline, 'pipeline.joblib')
```

### 4.4 ç‰ˆæœ¬å…¼å®¹

```python
# ä¿å­˜æ—¶è®°å½•ç‰ˆæœ¬
import sklearn
model_info = {
    'model': model,
    'sklearn_version': sklearn.__version__
}
joblib.dump(model_info, 'model_with_version.joblib')
```

---

## 5. å¸¸è§é”™è¯¯

| é”™è¯¯                           | åŸå›              | è§£å†³                      |
| ------------------------------ | ---------------- | ------------------------- |
| `ConvergenceWarning`           | æœªæ”¶æ•›           | å¢å¤§ `max_iter`           |
| `ValueError: unknown category` | æ–°ç±»åˆ«           | `handle_unknown='ignore'` |
| ç¨€ç–çŸ©é˜µå†…å­˜çˆ†ç‚¸               | æ ‡å‡†åŒ–ç ´åç¨€ç–æ€§ | `with_mean=False`         |
| åˆ†ç±»æ•ˆæœå·®                     | ç±»åˆ«ä¸å¹³è¡¡       | `class_weight='balanced'` |
| Pipelineå‚æ•°æ— æ•ˆ               | æ ¼å¼é”™è¯¯         | ç”¨ `æ­¥éª¤å__å‚æ•°å`       |
| ç»“æœä¸å¯å¤ç°                   | æœªè®¾éšæœºç§å­     | è®¾ `random_state=42`      |

---

## 6. ç‰ˆæœ¬æ£€æŸ¥

```python
import sklearn
print(sklearn.__version__)

from packaging import version
if version.parse(sklearn.__version__) >= version.parse("1.0"):
    print("æ–°ç‰ˆæœ¬åŠŸèƒ½å¯ç”¨")
```

---

## 7. æŸ¥çœ‹å¯ç”¨ä¼°è®¡å™¨

```python
from sklearn.utils import all_estimators

# æ‰€æœ‰åˆ†ç±»å™¨
classifiers = all_estimators(type_filter='classifier')

# æ‰€æœ‰å›å½’å™¨
regressors = all_estimators(type_filter='regressor')
```
