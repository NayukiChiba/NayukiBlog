---
title: NumPy 线性代数
date: 2026-01-06
category: MachineLearning/Basic/numpy
tags:
  - Python
  - NumPy
description: 使用 NumPy 进行线性代数运算，包括矩阵乘法、求逆、特征值等
image: https://img.yumeko.site/file/blog/NumpyLearning.jpg
status: public
---

# 线性代数

## 学习目标

- 掌握 NumPy 中的线性代数运算
- 理解矩阵运算的概念
- 学会使用 NumPy 的线性代数函数

## 为什么学习线性代数？

线性代数是机器学习的数学基础：

- **线性回归**：求解最小二乘问题
- **PCA 降维**：特征值分解
- **神经网络**：矩阵乘法是核心运算
- **推荐系统**：矩阵分解

NumPy 的 `np.linalg` 模块提供了完整的线性代数支持。

## 重要函数 (np.linalg 模块)

| 函数                    | 说明                          |
| ----------------------- | ----------------------------- |
| `np.dot(a, b)`          | 矩阵乘法（或向量点积）        |
| `a @ b`                 | 矩阵乘法运算符（Python 3.5+） |
| `np.linalg.inv(a)`      | 矩阵求逆                      |
| `np.linalg.det(a)`      | 计算行列式                    |
| `np.linalg.eig(a)`      | 计算特征值和特征向量          |
| `np.linalg.solve(a, b)` | 解线性方程组 Ax = b           |
| `np.linalg.norm(a)`     | 计算范数                      |

## 矩阵乘法 vs 元素乘法

这是最容易混淆的概念，必须区分清楚！

```python
A = np.array([[1, 2], [3, 4]])
B = np.array([[5, 6], [7, 8]])
```

### 元素乘法（对应位置相乘）

```python
print(A * B)
```

**结果**：

```
[[ 5 12]
 [21 32]]
```

**计算过程**：

```
1×5=5   2×6=12
3×7=21  4×8=32
```

### 矩阵乘法（线性代数乘法）

```python
print(A @ B)  # 推荐写法
# 或 print(np.dot(A, B))
```

**结果**：

```
[[19 22]
 [43 50]]
```

**计算过程**（行×列求和）：

```
(1×5+2×7)=19  (1×6+2×8)=22
(3×5+4×7)=43  (3×6+4×8)=50
```

**记忆方法**：

- `*` 星号：元素对元素
- `@` at符：矩阵乘矩阵

**矩阵乘法规则**：`(m×n) @ (n×p) = (m×p)`，第一个矩阵的列数必须等于第二个矩阵的行数。

## 向量点积

点积（内积）是两个向量对应元素相乘后求和。

```python
a = np.array([1, 2, 3])
b = np.array([4, 5, 6])

result = np.dot(a, b)
print(result)  # 32
```

**计算过程**：1×4 + 2×5 + 3×6 = 4 + 10 + 18 = 32

**几何意义**：

- 点积 > 0：两向量夹角 < 90°
- 点积 = 0：两向量垂直
- 点积 < 0：两向量夹角 > 90°

**应用场景**：

- 计算向量相似度（余弦相似度的分子）
- 神经网络中的加权求和

## 矩阵转置

转置就是把行变成列，列变成行。

```python
A = np.array([[1, 2, 3],
              [4, 5, 6]])  # 2×3 矩阵

print(A.T)
```

**结果**：

```
[[1 4]
 [2 5]
 [3 6]]
```

**形状变化**：2×3 → 3×2

**转置的性质**：

- `(A.T).T = A`：转置两次等于原矩阵
- `(A @ B).T = B.T @ A.T`：乘积的转置 = 转置的逆序乘积

## 行列式和逆矩阵

### 行列式

行列式是方阵的一个标量值，表示矩阵对空间的"缩放因子"。

```python
A = np.array([[4, 7], [2, 6]])

det = np.linalg.det(A)
print(det)  # 10.0
```

**2×2 矩阵行列式公式**：`|A| = ad - bc`

```
|4 7|
|2 6| = 4×6 - 7×2 = 24 - 14 = 10
```

**行列式的含义**：

- det = 0：矩阵不可逆（奇异矩阵）
- |det| > 1：矩阵放大空间
- |det| < 1：矩阵缩小空间

### 逆矩阵

逆矩阵满足：A × A⁻¹ = I（单位矩阵）

```python
A = np.array([[4, 7], [2, 6]])

A_inv = np.linalg.inv(A)
print(A_inv)
```

**结果**：

```
[[ 0.6 -0.7]
 [-0.2  0.4]]
```

**验证**：

```python
print(A @ A_inv)
```

**结果**：

```
[[1. 0.]
 [0. 1.]]
```

结果接近单位矩阵（可能有微小浮点误差）。

> **注意**：只有方阵（行数=列数）且行列式不为 0 才能求逆矩阵。

## 特征值和特征向量

**什么是特征值和特征向量？**

如果矩阵 A 作用于向量 v 后，结果仍然是 v 的倍数，即 Av = λv，那么：

- v 是 A 的**特征向量**
- λ 是对应的**特征值**

```python
A = np.array([[4, 2], [1, 3]])

eigenvalues, eigenvectors = np.linalg.eig(A)

print("特征值:", eigenvalues)
print("特征向量:\n", eigenvectors)
```

**结果**：

```
特征值: [5. 2.]
特征向量:
 [[ 0.894 -0.707]
  [ 0.447  0.707]]
```

**验证 Av = λv**：

```python
v = eigenvectors[:, 0]  # 第一个特征向量
lam = eigenvalues[0]    # 对应的特征值 5

print("A @ v =", A @ v)
print("λ * v =", lam * v)
```

两个结果应该相等。

**应用场景**：

- PCA 降维：找最大特征值对应的特征向量
- 图像压缩、推荐系统

## 解线性方程组

求解 **Ax = b** 类型的方程组。

**例题**：解方程组

```
2x + y = 5
x + 3y = 7
```

**NumPy 解法**：

```python
A = np.array([[2, 1], [1, 3]])
b = np.array([5, 7])

x = np.linalg.solve(A, b)
print(x)
```

**结果**：`[1.6 1.8]`

**含义**：x = 1.6, y = 1.8

**验证**：

```python
print(A @ x)  # 应该等于 b = [5, 7]
```

**为什么用 solve 而不用 inv？**

```python
# 两种方法等价，但 solve 更快更稳定
x = np.linalg.solve(A, b)  # 推荐
x = np.linalg.inv(A) @ b   # 不推荐
```

## 向量和矩阵范数

范数是衡量向量或矩阵"大小"的方式。

### L1 范数（曼哈顿距离）

```python
v = np.array([3, 4])
print(np.linalg.norm(v, ord=1))  # 7
```

**计算**：|3| + |4| = 7

**几何意义**：城市街区距离（只能走横竖）。

### L2 范数（欧几里得距离）

```python
print(np.linalg.norm(v, ord=2))  # 5
# 或 np.linalg.norm(v)  默认是 L2
```

**计算**：√(3² + 4²) = √25 = 5

**几何意义**：直线距离。

### 无穷范数

```python
print(np.linalg.norm(v, ord=np.inf))  # 4
```

**计算**：max(|3|, |4|) = 4

**含义**：最大的分量。

### 矩阵 Frobenius 范数

```python
A = np.array([[1, 2], [3, 4]])
print(np.linalg.norm(A))  # 5.477
```

**计算**：√(1² + 2² + 3² + 4²) = √30 ≈ 5.477

## 其他线性代数函数

| 函数                       | 说明          | 应用场景           |
| -------------------------- | ------------- | ------------------ |
| `np.linalg.matrix_rank(A)` | 矩阵的秩      | 判断方程组解的情况 |
| `np.linalg.svd(A)`         | 奇异值分解    | 降维、推荐系统     |
| `np.linalg.qr(A)`          | QR 分解       | 数值稳定的求解     |
| `np.linalg.cholesky(A)`    | Cholesky 分解 | 正定矩阵分解       |

## 浮点精度问题

矩阵运算中经常遇到浮点精度问题，结果可能有微小误差。

```python
A = np.array([[4, 7], [2, 6]])
result = A @ np.linalg.inv(A)

# 不要这样比较！
print(result == np.eye(2))  # 可能有 False

# 应该这样比较
print(np.allclose(result, np.eye(2)))  # True
```

`np.allclose()` 允许微小误差（默认容差 1e-8）。

## 小结

| 操作     | 函数/运算符           | 说明               |
| -------- | --------------------- | ------------------ |
| 元素乘法 | `A * B`               | 对应位置相乘       |
| 矩阵乘法 | `A @ B` 或 `np.dot()` | 线性代数乘法       |
| 转置     | `A.T`                 | 行列互换           |
| 逆矩阵   | `np.linalg.inv(A)`    | A × A⁻¹ = I        |
| 行列式   | `np.linalg.det(A)`    | 标量，判断是否可逆 |
| 解方程   | `np.linalg.solve()`   | 解 Ax = b          |

## 练习

运行代码文件查看完整演示：

```bash
python Basic/Numpy/06_linalg.py
```

**练习题**：

1. 计算向量 `[1, 2, 3]` 和 `[4, 5, 6]` 的点积
2. 解方程组：3x + 2y = 12, x + 4y = 10
3. 验证 2×2 矩阵 `[[1,2],[3,4]]` 与其逆矩阵相乘等于单位矩阵
